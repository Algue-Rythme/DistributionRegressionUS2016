{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out county/PUMA regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electoral data is by county, census data is by PUMA.\n",
    "\n",
    "Define regions that are connected components of PUMAs and counties. We'll do it for 2000 and 2010 geographies, as well as merged ones (for multi-year ACS files that use both geographies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are produced by [the MABLE geocorr tool](http://mcdc.missouri.edu/websas/geocorr12.html), by choosing source as `County` and target as either `PUMA (2012)` or `PUMA (2000--used in ACS data thru vintage 2011)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = '../pummeler/data/{}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "county_to_puma00 = pd.read_csv(data('county-to-puma00.csv.gz'), compression='gzip', skiprows=[1], dtype={'county': 'str'})\n",
    "county_to_puma10 = pd.read_csv(data('county-to-puma10.csv.gz'), compression='gzip', skiprows=[1], dtype={'county': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# puma00 of 77777 is combo of 01801, 01802, and 01905 in LA\n",
    "# make sure they're in the same CC...\n",
    "sub = county_to_puma00[(county_to_puma00.stab == 'LA')\n",
    "                 & ((county_to_puma00.puma2k == 1801)\n",
    "                  | (county_to_puma00.puma2k == 1802)\n",
    "                  | (county_to_puma00.puma2k == 1905))].copy()\n",
    "sub.puma2k = 77777\n",
    "county_to_puma00 = county_to_puma00.append(sub, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "def get_CCs(pairs):\n",
    "    A_cc = {}\n",
    "    B_cc = {}\n",
    "    \n",
    "    next_cc = count().next\n",
    "    \n",
    "    for A, B in pairs:\n",
    "        A_id = A_cc.get(A)\n",
    "        B_id = B_cc.get(B)\n",
    "        \n",
    "        if A_id is None:\n",
    "            if B_id is None:\n",
    "                A_cc[A] = B_cc[B] = next_cc()\n",
    "            else:\n",
    "                A_cc[A] = B_id\n",
    "        elif B_id is None:\n",
    "            B_cc[B] = A_id\n",
    "        elif A_id != B_id:\n",
    "            for k, v in A_cc.iteritems():\n",
    "                if v == B_id:\n",
    "                    A_cc[k] = A_id\n",
    "            for k, v in B_cc.iteritems():\n",
    "                if v == B_id:\n",
    "                    B_cc[k] = A_id\n",
    "    \n",
    "    ccs = [(set(), set()) for _ in xrange(next_cc())]\n",
    "    for k, v in A_cc.iteritems():\n",
    "        ccs[v][0].add(k)\n",
    "    for k, v in B_cc.iteritems():\n",
    "        ccs[v][1].add(k)\n",
    "    return [(As, Bs) for As, Bs in ccs if As or Bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ccs00_orig = get_CCs(\n",
    "    (row.county, (row.state, row.puma2k))\n",
    "    for _, row in county_to_puma00.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ccs10_orig = get_CCs(\n",
    "    (row.county, (row.state, row.puma12))\n",
    "    for _, row in county_to_puma10.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 982)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ccs00_orig), len(ccs10_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alaska's electoral districts are different from their counties.\n",
    "# Too much work to do it, so just pretend Alaska was one CC all along.\n",
    "def kill_alaska(ccs):\n",
    "    cs = set()\n",
    "    s_ps = set()\n",
    "    to_skip = set()\n",
    "    for i, (counties, state_pumas) in enumerate(ccs):\n",
    "        if any(state == 2 for state, puma in state_pumas):\n",
    "            cs |= counties\n",
    "            s_ps |= state_pumas\n",
    "            to_skip.add(i)\n",
    "    \n",
    "    return [(cs, s_ps)] + \\\n",
    "        [cc for i, cc in enumerate(ccs) if i not in to_skip]\n",
    "\n",
    "ccs00 = kill_alaska(ccs00_orig)\n",
    "ccs10 = kill_alaska(ccs10_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 979)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ccs00), len(ccs10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st_to_stab = county_to_puma00[['state', 'stab']].drop_duplicates()\n",
    "st_to_stab = dict(zip(st_to_stab.state, st_to_stab.stab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "\n",
    "def cc_names(ccs, fmt='{}_{}'):\n",
    "    state_counters = defaultdict(lambda: count(1))\n",
    "    names = []\n",
    "    for counties, state_pumas in ccs:\n",
    "        st, = {st for st, puma in state_pumas}\n",
    "        i = next(state_counters[st])\n",
    "        names.append(fmt.format(st_to_stab[st], i))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc_names00 = cc_names(ccs00, '{}_00_{:02}')\n",
    "cc_names10 = cc_names(ccs10, '{}_10_{:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_mappings(ccs, cc_names):\n",
    "    assert len(ccs) == len(cc_names)\n",
    "    county_region = []\n",
    "    puma_region = []\n",
    "    for name, (counties, pumas) in zip(cc_names, ccs):\n",
    "        st, = {st for st, puma in pumas}\n",
    "        stab = st_to_stab[st]\n",
    "        \n",
    "        for c in counties:\n",
    "            county_region.append((c, name))\n",
    "\n",
    "        for st, puma in pumas:\n",
    "            puma_region.append((st, puma, name))\n",
    "    \n",
    "    county_region_df = pd.DataFrame.from_records(\n",
    "        county_region, columns=['county', 'region'], index=['county']).sortlevel()\n",
    "    puma_region_df = pd.DataFrame.from_records(\n",
    "        puma_region, columns=['state', 'puma', 'region'], index=['state', 'puma']).sortlevel()\n",
    "    \n",
    "    return county_region_df, puma_region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "county_region_00, puma_region_00 = region_mappings(ccs00, cc_names00)\n",
    "county_region_10, puma_region_10 = region_mappings(ccs10, cc_names10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "county_region_00.to_hdf('regions.h5', 'county_region_00', format='table', complib='blosc', complevel=9, mode='w')\n",
    "puma_region_00.to_hdf('regions.h5', 'puma_region_00', format='table', complib='blosc', complevel=9)\n",
    "county_region_10.to_hdf('regions.h5', 'county_region_10', format='table', complib='blosc', complevel=9)\n",
    "puma_region_10.to_hdf('regions.h5', 'puma_region_10', format='table', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(st_to_stab.iteritems(), columns=['state', 'stab'], index='state') \\\n",
    "  .to_hdf('regions.h5', 'state_to_stab', format='table', complib='blosc', complevel=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
